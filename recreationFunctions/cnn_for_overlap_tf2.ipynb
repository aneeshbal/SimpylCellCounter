{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_for_overlap.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Rz1oSP5PCRmG",
        "wu5rzLInCphF",
        "HwJbDO6VKIvW",
        "JVLT0rEFKLLw",
        "12P92oPnEMK-",
        "cyOxP2MqEJZc",
        "x6PJF6TeExYK",
        "KWEJclsRXIaW"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPv3glB6KNIF/upYttd10y4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneeshbal/SimpylCellCounter/blob/master/recreationFunctions/cnn_for_overlap_tf2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz1oSP5PCRmG",
        "colab_type": "text"
      },
      "source": [
        "## Initialize Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2An5sCfCM16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu5rzLInCphF",
        "colab_type": "text"
      },
      "source": [
        "## Create Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kxwPIchCoc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createImg(num_of_objects):\n",
        "    \n",
        "    global im, sizes, intensities\n",
        "    \n",
        "    im = np.random.randint(165, 200, size = (100, 100)).astype('uint8')\n",
        "    obj_num = num_of_objects\n",
        "    circle_centers = np.random.randint(25, 75, size = (obj_num, 2))\n",
        "    intensities = np.random.randint(80, 90, size = (obj_num, 1)).astype('int')\n",
        "    sizes = np.random.randint(8, 12, size = (obj_num, 1)).astype('int')\n",
        "\n",
        "    for jj in range(len(circle_centers)):\n",
        "        cv2.circle(im, (circle_centers[jj][0], circle_centers[jj][1]), sizes[jj], int(intensities[jj]), -1)\n",
        "        \n",
        "    ## blur image\n",
        "    im = cv2.medianBlur(im, 3)\n",
        "    im = cv2.GaussianBlur(im, (3,3), 9)\n",
        "    \n",
        "    return im"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73bJsmXoCSvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = []\n",
        "imgSize = 100\n",
        "overlapping_cells = 5\n",
        "cells_per_class = 10000\n",
        "len_train = int(overlapping_cells * cells_per_class)\n",
        "\n",
        "def create_training_data():\n",
        "    for j in tqdm(range(0, len_train)):\n",
        "        num_obj = np.random.randint(1,overlapping_cells)\n",
        "        img = createImg(num_obj)\n",
        "        label = int(num_obj-1)\n",
        "        ret, img2 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        training_data.append([img2, label])\n",
        "        \n",
        "        \n",
        "create_training_data()\n",
        "print(len(training_data))\n",
        "\n",
        "import random\n",
        "random.shuffle(training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZC2g3tVCzpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, labels in training_data:\n",
        "    X.append(features)\n",
        "    y.append(labels)\n",
        "  \n",
        "  \n",
        "X = np.array(X).reshape(-1, imgSize, imgSize, 1)\n",
        "y = np.array(y)\n",
        "\n",
        "X = X.astype('float32')/255.\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9_RrwdJC9ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "del X, y, training_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cj2AQa8r4kQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if training on TPU...\n",
        "## confirm sizes of arrays...if any array > 2GB, won't fit in TPU\n",
        "\n",
        "print(X_train.nbytes/1e9)\n",
        "print(X_test.nbytes/1e9)\n",
        "print(y_train.nbytes/1e9)\n",
        "print(y_test.nbytes/1e9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hdt8n4jDTpv",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwJbDO6VKIvW",
        "colab_type": "text"
      },
      "source": [
        "### Model 1 - Standard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIg4YijtDSnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.constraints import *\n",
        "from tensorflow.keras.regularizers import *\n",
        "\n",
        "def make_model():\n",
        "  input_img = Input(shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]))\n",
        "\n",
        "  conv1 = Conv2D(64, 3, activation='relu', padding='same')(input_img)\n",
        "  conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "  pool1 = MaxPooling2D((2,2))(conv1)\n",
        "\n",
        "  conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "  conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "  pool2 = MaxPooling2D((2,2))(conv2)\n",
        "\n",
        "  conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "  conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "  pool4 = MaxPooling2D((2,2))(conv3)\n",
        "\n",
        "  avg = GlobalAveragePooling2D()(pool4)\n",
        "  dense = Dense(y_train.shape[1], activation='softmax')(avg)\n",
        "\n",
        "  model = Model(input_img, dense)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVLT0rEFKLLw",
        "colab_type": "text"
      },
      "source": [
        "### Model 2 - Residual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BiDQh9_KKiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convolution - 85% on standard set validation data\n",
        "## check dropout and additional layers!\n",
        "\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.constraints import *\n",
        "from tensorflow.keras.regularizers import *\n",
        "\n",
        "p = 'same'\n",
        "\n",
        "def additive_block(x, filters, size, activation='relu', drop1=0.3, drop2=0.3):\n",
        "\n",
        "  conv1 = Conv2D(filters, size, padding=p)(x)\n",
        "  a1 = Activation('relu')(conv1)\n",
        "  conv2 = Conv2D(filters, size, padding=p)(a1)\n",
        "  p1 = MaxPooling2D((2,2))(conv2)\n",
        "  d1 = Dropout(drop1)(p1)\n",
        "  a2 = Activation('relu')(d1)\n",
        "\n",
        "  conv3 = Conv2D(filters, size, padding=p)(conv2)\n",
        "  a3 = Activation('relu')(conv3)\n",
        "  conv4 = Conv2D(filters, size, padding=p)(a3)\n",
        "  p2 = MaxPooling2D((2,2))(conv4)\n",
        "  d2 = Dropout(drop2)(p2)\n",
        "  a4 = Activation('relu')(d2)\n",
        "  add1 = Concatenate()([a2, a4])\n",
        "  return add1\n",
        "\n",
        "\n",
        "def make_model():\n",
        "  input_img = Input(shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]))\n",
        "  downblock1 = additive_block(input_img, 64, 3) # 50-size\n",
        "  downblock2 = additive_block(downblock1, 128, 3) # 25-size\n",
        "  downblock3 = additive_block(downblock2, 256, 3) # 12-size\n",
        "  avg = GlobalAveragePooling2D()(downblock3)\n",
        "  dense = Dense(y_train.shape[1], activation='softmax')(avg)\n",
        "\n",
        "  model = Model(input_img, dense)\n",
        "  return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12P92oPnEMK-",
        "colab_type": "text"
      },
      "source": [
        "# GPU Training \n",
        "#### Preferred form of training, but will take longer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCBBtbq4EPkM",
        "colab_type": "text"
      },
      "source": [
        "## Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSR0SDEHEN-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-4\n",
        "\n",
        "model = make_model()\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adamax(learning_rate=lr),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "print('Model built and compiled')\n",
        "  \n",
        "def scheduler(epoch):\n",
        "  if epoch < 20:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(0.005 * (20 - epoch))\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kamP4M76EXIj",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2GyiAYJEY9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h = model.fit(X_train, y_train, \n",
        "              validation_data=(X_test, y_test),\n",
        "              batch_size=128,\n",
        "              epochs=100,\n",
        "              callbacks=[callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqKz_t06Eh7S",
        "colab_type": "text"
      },
      "source": [
        "## Plot Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evuwScYsEjEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(h.history['loss'])\n",
        "plt.plot(h.history['val_loss'])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(h.history['accuracy'])\n",
        "plt.plot(h.history['val_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyOxP2MqEJZc",
        "colab_type": "text"
      },
      "source": [
        "# TPU Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiGnHKM9qc_t",
        "colab_type": "text"
      },
      "source": [
        "## Compile Model on TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAEtOE__qeug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxzaF7Ycq_gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "\n",
        "with strategy.scope():\n",
        "  model = make_model()\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "print('Model built and compiled')\n",
        "  \n",
        "def scheduler(epoch):\n",
        "  if epoch < 20:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(0.05 * (20 - epoch))\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwFVlGfD8sK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newlr = []\n",
        "for j in range(0, 500):\n",
        "  newlr.append(scheduler(j))\n",
        "plt.plot(newlr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWNzU-QSqihA",
        "colab_type": "text"
      },
      "source": [
        "## Format Data and Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCpLJS0VEJwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for data as tensors \n",
        "b_s = 1024  ## Best batch_size is to be determined for classification problems...\n",
        "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_data = train_data.shuffle(buffer_size=100).batch(b_s)\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "test_data = test_data.shuffle(buffer_size=100).batch(b_s)\n",
        "print('Formatting data...')\n",
        "\n",
        "# set this to avoid retracing warnings during training, note that other tensorflow warnings will be disabled as well!\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "print('Beginning training...')\n",
        "## train model\n",
        "with strategy.scope():\n",
        "  h = model.fit(train_data,\n",
        "                validation_data=test_data,\n",
        "                batch_size=b_s,\n",
        "                epochs=50,\n",
        "                callbacks=[callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6PJF6TeExYK",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbctdPWTGL4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B48IRWV7G2h1",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzL_KLd0EX4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d_imgs = model.predict(X_test)\n",
        "print(d_imgs.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1iktqMwHAp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index = 196\n",
        "plt.figure()\n",
        "plt.imshow(X_test[index,:,:,0], cmap=plt.cm.gray)\n",
        "print('Ground truth is', np.argmax(y_test[index])+1)\n",
        "print('Prediction is', np.argmax(d_imgs[index])+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUQUI9qwcIHL",
        "colab_type": "text"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgyHgzFlcIzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My Drive/SCC_1x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcfMv7mucMDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## even if you cd into a directory, still define the full path when saving...had some issues with colab with this before\n",
        "\n",
        "#model.save('/content/drive/My Drive/SCC_1x/res_{}x.h5'.format(overlapping_cells))\n",
        "#model.save_weights('/content/drive/My Drive/SCC_1x/res_{}x_weights.h5'.format(overlapping_cells))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWEJclsRXIaW",
        "colab_type": "text"
      },
      "source": [
        "# Plot Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKfHjLUgXJBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## plot model architecture\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}